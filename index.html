<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <b>Wenyu Zhang<sup>1</sup>,</b>
            </span>
            <span class="author-block">
              <b>Wei En Ng<sup>2</sup>,</b>
            </span>
            <span class="author-block">
              <b>Lixin Ma<sup>3*</sup>,</b>
            </span>
            <span class="author-block">
              <b>Yuwen Wang<sup>2*</sup>,</b>
            </span>
            <span class="author-block">
              <b>Junqi Zhao<sup>4*</sup>,</b>
            </span>
            <br />
            <span class="author-block">
              <b>Allison Koenecke<sup>5</sup>,</b>
            </span>
            <span class="author-block">
              <b>Boyang Li<sup>4</sup>,</b>
            </span>
            <span class="author-block">
              <b>Lu Wang<sup>1</sup></b>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>Institute for Infocomm Research (I<sup>2</sup>R), Agency for
              Science, Technology and Research (A*STAR),
            </span>
            <br />
            <span class="author-block">
              <sup>2</sup>National University of Singapore (NUS),
            </span>
            <span class="author-block">
              <sup>3</sup>Tongji University,
            </span>
            <br />
            <span class="author-block">
              <sup>4</sup>Nanyang Technological University (NTU),
            </span>
            <span class="author-block">
              <sup>5</sup>Cornell University
            </span>
            <span class="author-block">
              <small>
                <sup>*</sup>Contributed equally to this work; authors are listed in
                alphabetical order.
              </small>
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.12693"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.12693"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/zwenyu/SPHERE-VLM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/wei2912/SPHERE-VLM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Current vision-language models may grasp basic spatial cues and simple
            directions (e.g. left, right, front, back), but struggle with the
            multi-dimensional spatial reasoning necessary for human-like understanding
            and real-world applications.
          </p>
          <p>
            To address this gap, we develop SPHERE (<b><u>S</u></b>patial
            <b><u>P</u></b>erception and <b><u>H</u></b>ierarchical
            <b><u>E</u></b>valuation of <b><u>RE</u></b>asoning), a hierarchical
            evaluation framework supported by a new human-annotated dataset.
            SPHERE systematically probes models across increasing levels of complexity,
            from fundamental skills to multi-skill integration and high-level reasoning
            that combines spatial, visual, and logical understanding.
          </p>
          <p>
            Benchmark evaluation of state-of-the-art models reveals significant
            deficiencies, especially in reasoning about distance and proximity,
            understanding both egocentric and allocentric perspectives, and applying
            spatial logic in physical contexts.
            These findings expose critical blind spots in existing models and underscore
            the need for more advanced spatial reasoning techniques, driving the
            development of vision-language models that align more closely with human
            spatial cognition.
          </p>
          <p>
            The SPHERE benchmark is available at
            <a href="https://github.com/zwenyu/SPHERE-VLM">this repository</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Dataset Viewer</h2>

          <iframe
            src="https://huggingface.co/datasets/wei2912/SPHERE-VLM/embed/viewer/counting_only-paired-distance_and_counting/train"
            frameborder="0"
            width="100%"
            height="560px"
          ></iframe>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhang2024sphere,
  title={SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation},
  author={Zhang, Wenyu and Ng, Wei En and Ma, Lixin and Wang, Yuwen and Zhao, Jungqi and Koenecke, Allison and Li, Boyang and Wang, Lu},
  journal={arXiv preprint arXiv:2412.12693},
  year={2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2412.12693">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/SPHERE-VLM/sphere-vlm.github.io" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from
            <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and
            licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
              Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
